{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pytorch version:2.2.1+cu121\n",
      " torchvision version:0.17.1+cu121\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "import torchvision\n",
    "\n",
    "print(f\"Pytorch version:{torch.__version__}\\n torchvision version:{torchvision.__version__}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "训练集大小: 40000\n",
      "验证集大小: 10000\n",
      "测试集大小: 10000\n",
      "类别标签: ['airplane', 'automobile', 'bird', 'cat', 'deer', 'dog', 'frog', 'horse', 'ship', 'truck']\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 32, 32])"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# 数据预处理\n",
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(), # 转换为张量\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)) # 归一化\n",
    "])\n",
    "\n",
    "# 加载 CIFAR-10 数据集\n",
    "dataset = torchvision.datasets.CIFAR10(root='./data', train=True, download=False, transform=transform)\n",
    "test_dataset = torchvision.datasets.CIFAR10(root='./data', train=False, download=False, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = len(dataset) - train_size\n",
    "train_dataset, val_dataset = random_split(dataset, [train_size, val_size])\n",
    "\n",
    "# 打印数据集大小\n",
    "print('训练集大小:', len(train_dataset))\n",
    "print('验证集大小:', len(val_dataset))\n",
    "print('测试集大小:', len(test_dataset))\n",
    "\n",
    "# 打印类别标签\n",
    "classes = dataset.classes\n",
    "print('类别标签:', classes)\n",
    "\n",
    "#数据集查看\n",
    "image, label = train_dataset[0]\n",
    "\n",
    "# image, label #查看第一条训练数据\n",
    "image.shape  #查看数据的形状\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Clipping input data to the valid range for imshow with RGB data ([0..1] for floats or [0..255] for integers).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image shape: (3, 32, 32)\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaAAAAGzCAYAAABpdMNsAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8g+/7EAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAsiklEQVR4nO3de3TU9Z3/8VeGMBNCboaQW5NwEYEiBFcUTFWKkHLxty4qu/V2foXW6uIGd5V226anarW7v7j2/NTaIm7PWtieLWptC/50W11FExYFLChLkUoNRIGGJAWaTC7mOt/fH9bsRkE+b8jwScLzcc6cQ5I377wn30le+c5M3pMQBEEgAADOsJDvAQAAZycCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEnAHLli1TQkLCCS+///3vfY8InHEJ7IID4m/Lli3at29fn/cFQaDly5dr7NixeuuttzxNBviT6HsA4GxQUlKikpKSPu/bvHmz2tradNNNN3maCvCLu+AAT9atW6eEhATdeOONvkcBvOAuOMCDrq4u5eXlafLkydq8ebPvcQAvOAMCPHjhhRd09OhR7n7DWY0AAjxYt26dhg8frs9//vO+RwG84S444AxraWlRTk6O5s6dq2effdb3OIA3nAEBZ9iGDRt49hsgzoCAM27RokXavHmz6uvrlZyc7HscwBvOgIAz6A9/+INeeuklXXPNNYQPznoEEHAGPfXUU+ru7ubuN0DcBQecUSUlJdq/f79qa2s1bNgw3+MAXhFAAAAvuAsOAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvBtwrosZiMdXW1io1NVUJCQm+xwEAGAVBoObmZuXn5ysUOvF5zoALoNraWhUWFvoeAwBwmg4ePKiCgoITfnzABVBqauoH/xgt9zsImw2fINF4r2Ms5l7bYmut0aPca5uPmlrnTf6Ue+uorffI5BGm+u62951rj+5vN/UerDLG2H7Javzj792Lo4bb7GAWdi9NM67dizba6i0uvbzEVP/qf26J0yTx1/vz/ATiFkCrVq3Sd7/7XdXV1Wn69On6/ve/r5kzZ570//Xe7RaSewBZ7qmz3q0Xz3sBP+HU9GOMc4SGufdOGGZrbun9Qb2hv/XrPUj3eCRYjr1kv92eDSw3K/PXL343rMTEAfd7f9yc7OselychPPXUU1q5cqXuuecevfHGG5o+fboWLFighoaGeHw6AMAgFJcAevDBB3XLLbfoi1/8oqZMmaLHHntMycnJ+tGPfvSx2o6ODkWj0T4XAMDQ1+8B1NnZqR07dqi0tPS/P0kopNLSUm3Z8vH7MisqKpSent574QkIAHB26PcAOnLkiHp6epSTk9Pn/Tk5Oaqrq/tYfXl5uZqamnovBw8e7O+RAAADkPdHwyKRiCKRiO8xAABnWL+fAWVlZWnYsGGqr6/v8/76+nrl5ub296cDAAxS/R5A4XBYM2bM0MaNG3vfF4vFtHHjRpWU2J7/DgAYuuJyF9zKlSu1dOlSXXTRRZo5c6Yefvhhtba26otf/GI8Ph0AYBCK20ty/+AHP+j9Q9QLLrhAjzzyiGbNmnXS/xeNRpWenq7x8z6lYY5bC44Ynrr9x7ebnGs/+A+2chvLH8cZD1O6obbb1lptxnqLQfqHpWbDR5rKc7IynWvrDxufyJM6zLl0eHKKqXVXo2E9SId1g8PZcmMZvJqampSWlnbCj8ftSQgrVqzQihUr4tUeADDI8XIMAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvvL8cw4ksn3mDRiS5vUxDW9h9N0zoL5NNc1Ruetm59t+f+fgL7n2yOK4SMW4cwhnW1Woqrz9sqzdp7nEu7Wo+O25Yqcb65rhMMfRxBgQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwYsLvgnv3RE0oMueVj47FDzn0vKy01zbH8xmXOtf/+nHEXnPsKLrsR7qUzJuaZWkc7k0z171TXONcOD5taq6vdUBzPr7fRiBy3PYcfer++I06TDF7nGGptGyClqLHe8h1UlzPS1Duoj98ewBGGnxPvv9//n58zIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMCLAbuKZ9pnJyoy3G28I4dSnPuGs21rZDLC7l+iJaXTTL1/d+Bd59rkZNsykYumTnWuTQvZer+8Z7+pXl3upXPmXmxqXf32r51rJ4wfZeq9+3dHnWsLsmy9J2RlmOp3Je1zrs0qyDH13vN2vXPtMfcviVnMWP/HONVK0uWpw0z13WH3PU/HjKt1LEuYblqy2NQ7N+S++6r63Zeda7t6YvrlGyf/qnMGBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvBiwu+AKU9OVFB7uVDt1ovvVaE9KM82xffMu59o5RVNMvT+TO8G5Njk/w9Q71t7oXBsKHTP1njy201S/v8699qLPXGLq3bDffRfc1GTbzT2W7V57yZTJpt6JLQ2m+jrD6J+fvdDU+0jRHufaHz7h/vWWpIOm6oGjutl9t5skHTbUXjzJNkta2jnOtVsrX7c1b2xxLp0yxf1nZ6zHbbMfZ0AAAC/6PYC+/e1vKyEhoc9l8mTbb4cAgKEvLnfBnX/++XrppZf++5MkDth7+gAAnsQlGRITE5WbmxuP1gCAISIujwG98847ys/P1/jx43XTTTfpwIEDJ6zt6OhQNBrtcwEADH39HkCzZs3S2rVr9fzzz2v16tWqqanR5Zdfrubm5uPWV1RUKD09vfdSWFjY3yMBAAagfg+gRYsW6a/+6q9UXFysBQsW6Je//KUaGxv105/+9Lj15eXlampq6r0cPDhYn7gJALCI+7MDMjIyNHHiRFVXVx/345FIRJFIJN5jAAAGmLj/HVBLS4v27dunvLy8eH8qAMAg0u8B9NWvflVVVVV699139dprr+maa67RsGHDdMMNN/T3pwIADGL9fhfcoUOHdMMNN+jo0aMaPXq0LrvsMm3dulWjR4829fl95whFFHaqLUhLce67v9b2LLvdh15zru2sM+yckXTB+Auca9sObDX1DhlWvfzF7Pmm3heEkk31E/+i2Ll2ytjxpt6dFy5wrs3NyjL1zi5yXzm0/5DtdpWUkWmqn1o61bl21/ZDpt4vvei+XudseYTWslrH6sILFpvqaxMN328tO029s8bmO9eGct2/f0Jd3dKek38V+z2Annzyyf5uCQAYgtgFBwDwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHgR95djOFWjx05QUlKSU217rN25b2ZSt2mOmQXuO7va2913h0lSqD3mXJscLTL1zspw/93itZ89Yer9/HumcmUYakN/7bb/70OdYfc9WQ1HWky9cw27rwoK3G6rH2o58K6pPmm3e/0v37RtbHvHVI3T1V75sql+8o1fdq5NvuwSU++kbvefQUkx97jo7HT7WcgZEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAODFgF3FkxqWRrhuZQm5r2MJhd1XT0hSt9xXrLTFbGt+LKNs+sHPTL0P1b3vXNsdmFqr1lauQ4ba7n+2rQUqPneUc23swimm3kkp2c614dc3m3r/7sUaU321oXaHqTPOtHX1zab6K1/f41w7duZkU+8kQwK0xQyrxjrcyjgDAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXgzYXXDpI1OUPMJtD1us230HW8h1v9yfdBv2taWEjHne4L4lrSjmvttNkjoN+90uHGdqrRsvSDXVH9jvvvvq0H/ZZpk8xf1rnl9k2wOYndnmXPt2g223m3vnD+w31p8N7rrhUufagotmmnr/9Vceso7jrMtY/8yrLzjXXpcbNfW+oHiOc233MfdbbeD4M5kzIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4MWA3QUX6oopNMxtd1e0pcW9b6LtKicbev/upf9n6p3S8q5zbVa7qbXcO0vbbWvMVNzgvttNkpIMi8/yh9tmyc8Y71zbVrnd1Lsu8TXn2pBxuZt1F5xti93glGesX3j1l5xr9+x337soSTnGWeqN9fHy1M+3mOobaxuca6v3HHCujQVuyyg5AwIAeGEOoE2bNumqq65Sfn6+EhIStGHDhj4fD4JAd999t/Ly8jRixAiVlpbqnXfe6a95AQBDhDmAWltbNX36dK1ateq4H3/ggQf0yCOP6LHHHtO2bds0cuRILViwQO3txvuQAABDmvkxoEWLFmnRokXH/VgQBHr44Yf1rW99S4sXL5Yk/fjHP1ZOTo42bNig66+//vSmBQAMGf36GFBNTY3q6upUWlra+7709HTNmjVLW7Yc/8Gxjo4ORaPRPhcAwNDXrwFUV1cnScrJ6fsckpycnN6PfVRFRYXS09N7L4WFhf05EgBggPL+LLjy8nI1NTX1Xg4ePOh7JADAGdCvAZSbmytJqq/v+6z4+vr63o99VCQSUVpaWp8LAGDo69cAGjdunHJzc7Vx48be90WjUW3btk0lJSX9+akAAIOc+VlwLS0tqq6u7n27pqZGO3fuVGZmpoqKinTHHXfoH/7hH3Teeedp3Lhxuuuuu5Sfn6+rr766P+cGAAxyCUHguDPhTyorK3XFFVd87P1Lly7V2rVrFQSB7rnnHv3whz9UY2OjLrvsMj366KOaOHGiU/9oNKr09HQ99rd/qxGRiNP/aTH8jVG33FfrSNL2dWuca18/amqt498peXxv21rHdTVIurG+2FCbbextucO229jb8tuZ9a/cbEuBJPclKFKHsfdA8Vlj/YVjznGubcm3fLdJuRPzTfV71m08edGf/LzL1HpQa2pq+sSHVcxnQHPmzNEnZVZCQoLuu+8+3XfffdbWAICziPdnwQEAzk4EEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADAC/MqnjPl/OROpUQS3Iozws59t//iNdMcdYb9btY9Zm8YapuNveOpyVj/n4baMcbeFtbfttxvVVKbsfcRY/1g3e820lBbZexd9d4fnWuX5Geaetdu3mWqrzTsdzvX1Fk65vhjUJIyjK9mk2X4siQbviG6e6RXq09exxkQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4MWAXcWTeH6gxOSYU+2RQwec+67bsdc0x5zPpTvXbnjRtqRmIK3XGSjei2Pv4cZ641YTk8449h5IJhhq/ytuU0hZYyea6qMpb5vqE/f9wbk2OcfUWqWfKXGuvfbPx5t6t7Ufc65NDqU417a+36VXV244aR1nQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwIsBuwsulFOg0Mgkp9rt//acc99DxjkKprrXVr9obI4zqstYf9RQm2DsfbZo8D3An1Rv3W6qTw5HTfVFw9xrL7nkU6be3d3tzrVpYduP9GS573eLdbv37XE8teEMCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPBiwK7iUXu6NGyEU+n2DTXObS8yjlE0frxzbZveNHbHUBH4HmCAOmyovThi6/3rDvfajTV/MPU+xzaKZo9xr01OdFsx9qH2dsNaoPZOU+/EmPs5SGen+0ogdbotvuIMCADgBQEEAPDCHECbNm3SVVddpfz8fCUkJGjDhg19Pr5s2TIlJCT0uSxcuLC/5gUADBHmAGptbdX06dO1atWqE9YsXLhQhw8f7r088cQTpzUkAGDoMT8JYdGiRVq0aNEn1kQiEeXm5p7yUACAoS8ujwFVVlYqOztbkyZN0m233aajR0/80l4dHR2KRqN9LgCAoa/fA2jhwoX68Y9/rI0bN+qf/umfVFVVpUWLFqmnp+e49RUVFUpPT++9FBYW9vdIAIABqN//Duj666/v/fe0adNUXFysc889V5WVlZo3b97H6svLy7Vy5cret6PRKCEEAGeBuD8Ne/z48crKylJ1dfVxPx6JRJSWltbnAgAY+uIeQIcOHdLRo0eVl5cX708FABhEzHfBtbS09Dmbqamp0c6dO5WZmanMzEzde++9WrJkiXJzc7Vv3z597Wtf04QJE7RgwYJ+HRwAMLiZA2j79u264ooret/+8PGbpUuXavXq1dq1a5f+9V//VY2NjcrPz9f8+fP1ne98R5GIbdHTm5se0oiI2wnabsMiruuvOHnN/9Qei9n+A4BT0mDY7SZJqYbaZltrffl/JZjqPzPnEufaxqjtx25SKOxcG4vZdsHJ8PMtFHK/w8y11hxAc+bMURCc+Cf+Cy+8YG0JADgLsQsOAOAFAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8KLfXw+ovzTtrlHHcLfadkPf/Cm2nXSdne67lY7/knsAXLwXx94zHH+WfGj+lX9uqk/Lcn8Zmdx2437J7hbn0vZO2ytKhwznIDFDXHSry/HzAwDgAQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPBiwK7ieW+rFElwq3VfgiFljs81zdHS6L4G42xx3TRb/VO/ic8cgKt827e9MrOyTPWxbvf1OrFYm6l3d8x9HVhSYrKpt+UcJBbrdq7tSnTryxkQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwYsDugtvb6D7cJZ9275s1Pts0x7tP7jHVD0bzzhtpqr/x7itN9Sk/etq5Nte4yurffu5e+56ttRxXEUqSrh1n6/3zGls9Ts+zB2313zLsdpOkxJD7vrbkxCRT71jIfQdbOGbZjGk7A2nvjDrXxhT0++cHAKDfEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8G7CqeUZKGO9bO/cKfOfcNa4ppjn976tem+sHoC1+7w1SfOf5CU/31K8Y61yZ315l6z73evXbzbvdVIpKUldjmXJvR9rap988rjLthBogZxvodhlrjNiPFc5vRsYZjpvrsLPf1Op3t7abe3Z0t7rVyv81adXe6rwTqaHer5QwIAOAFAQQA8MIUQBUVFbr44ouVmpqq7OxsXX311dq7d2+fmvb2dpWVlWnUqFFKSUnRkiVLVF9f369DAwAGP1MAVVVVqaysTFu3btWLL76orq4uzZ8/X62trb01d955p5599lk9/fTTqqqqUm1tra699tp+HxwAMLiZnoTw/PPP93l77dq1ys7O1o4dOzR79mw1NTXp8ccf17p16zR37lxJ0po1a/TpT39aW7du1SWXXPKxnh0dHero6Oh9Oxq1PVAMABicTusxoKamJklSZmamJGnHjh3q6upSaWlpb83kyZNVVFSkLVu2HLdHRUWF0tPTey+FhYWnMxIAYJA45QCKxWK64447dOmll2rq1KmSpLq6OoXDYWVkZPSpzcnJUV3d8Z9eW15erqampt7LwYOD8+mpAACbU/47oLKyMu3evVubN28+rQEikYgikchp9QAADD6ndAa0YsUKPffcc3rllVdUUFDQ+/7c3Fx1dnaqsbGxT319fb1yc3NPa1AAwNBiCqAgCLRixQqtX79eL7/8ssaN6/u3yzNmzNDw4cO1cePG3vft3btXBw4cUElJSf9MDAAYEkx3wZWVlWndunV65plnlJqa2vu4Tnp6ukaMGKH09HTdfPPNWrlypTIzM5WWlqbbb79dJSUlx30GHADg7GUKoNWrV0uS5syZ0+f9a9as0bJlyyRJDz30kEKhkJYsWaKOjg4tWLBAjz76qHmwSROlpGFutUXFs537vrzW9piVZZfVQHLX/3bfj5eb1mnq3bD/kKm+qOgy59rooddMvVtqX3eunTnhIlPvzgb3vVo/ffBFU++B5BxD7YP/PMvU+wff3OZc+/RRU+u46mw7Yqpvb0t2rg0l2h6O6A65745ra2sw9Q6FDBFg2AXX3tnjVGcKoCAITlqTlJSkVatWadWqVZbWAICzDLvgAABeEEAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABenPLLMcTbxBlSctittrZ6t3Pf8qfjt1xntLH+D3GZ4gPFl011rm18e62pd2N7pqn+3d/9uXNtZor7ug9JSqtzP/Z11cd/TaoT+dr3f+tc22TqPLDcfaf7i0C2t9hesfjLd487edGftNxfY+r9q8OmcpMjjbaVNpnZBScv+lDKFNsw3e6rrxJDxnOKmOMPWUmJ7qXqGtYlaedJ6zgDAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB4QQABALwggAAAXgzYXXDnjJZGRtxqf/e7TfEdxtH/+c5wU/237+pyrq01ztLwxmvOte3GrXR1dbb6/Uf2OtfmFtg26k3Ncp/lwVW2uQfSfrfzEtxrr7zS1js77L73rPHIMVPvzvZO59q/vN72/bPrIffvn9+bOkuvbdpnqp9aPNO5NjEtxTZMt/ueuVhSkq23YXdc2HK+0tbh9undOwIA0H8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwN2FU9zstTjuIpn12vuKzmsSka51x6qtc0x+wr32ideMbXWhn92XyUy4Spb78Z2W31KsnttW9S45ifsXmtdZxRPC2wbhzT3L9xrU4zbWDq73damSFJiku131pihNjnJcEORNH+S+7KkNe7boCRJBdmppvrO7jT34pDtACWG3b+KoZhxzY/hHKRb3e61oaCfPzsAAP2IAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8GLC74PZ3hpSUkOBU+8tXe+I2x9zr3Wujxh1p46e41y6utvWuPOhee4mttSZcYPwPbe6l4XC6qXVamvv+sPl/dtjUu+FN99pjps7SjV+2LYPLyMhwrg3F3Hd2SVKi4dfQcKJt11h3mvsesxTDdZSkrAnbnWtz9rrvu5OkpMQsU/2uzYecayd+ZqKpd2LI/XgmJ9p+pFt29cVi7r073nf7mcwZEADAC1MAVVRU6OKLL1Zqaqqys7N19dVXa+/evmtm58yZo4SEhD6X5cuX9+vQAIDBzxRAVVVVKisr09atW/Xiiy+qq6tL8+fPV2tra5+6W265RYcPH+69PPDAA/06NABg8DPdYfj888/3eXvt2rXKzs7Wjh07NHv27N73JycnKzc3t38mBAAMSaf1GFBT0wcvCJWZmdnn/T/5yU+UlZWlqVOnqry8XG1tJ34UuqOjQ9FotM8FADD0nfKz4GKxmO644w5deumlmjp1au/7b7zxRo0ZM0b5+fnatWuXvv71r2vv3r36xS9+cdw+FRUVuvfee091DADAIHXKAVRWVqbdu3dr8+bNfd5/66239v572rRpysvL07x587Rv3z6de+65H+tTXl6ulStX9r4djUZVWFh4qmMBAAaJUwqgFStW6LnnntOmTZtUUFDwibWzZs2SJFVXVx83gCKRiCKRyKmMAQAYxEwBFASBbr/9dq1fv16VlZUaN27cSf/Pzp07JUl5eXmnNCAAYGgyBVBZWZnWrVunZ555Rqmpqaqrq5Mkpaena8SIEdq3b5/WrVunK6+8UqNGjdKuXbt05513avbs2SouLo7LFQAADE6mAFq9erWkD/7Y9H9as2aNli1bpnA4rJdeekkPP/ywWltbVVhYqCVLluhb3/pWvw0MABgazHfBfZLCwkJVVVWd1kAfyj+nUMlJbs8SP6Ya574lI21zzCk+37m2tqHF1LtN7vVjP3/U1Hv3/3Wv3f5LU2t94ZIxpvr2kPtT6zPSPvkxxY/q7nZfwLdwTqqp98/ebHauHWu8XeXmjzXVNx5z3zaXEk4z9U5Ldq/v7LRsD5OSw0nOtYmxTlPvpLD7frd6U2dp82b3nymSdOV899thw+53Tb2TEt2/hm3upZKkbsPeQMsuuLYOdsEBAAYwAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4MUpvx5QvDVX/17d4QSn2iZD3+KZtjmiR44417Y32hZ+tBs2jySFTa11oWH5eN1hW+8jDe+Z6o8ZNhTVHvmjqXeS4RYcs22R0R5D7WTbBiG1HKk21Xe2nPhVhT8qmphimyXqfuOy/sBICic713bHbK+GnJ3hXnvyvf19ZRp/NS8aa1h/lOh+LCWpu9t9DZMMa3skKdbp/kMoOTnDuTYIsYoHADCAEUAAAC8IIACAFwQQAMALAggA4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwN2F9yhPd2KOE433NB34hTbHC2GHVyJxq9mzLAS6phtfZSSDKupMo29o4bVVJJkWcHW3m3r3WaoT3JfSyZJKjLUphh3wbUds+286zYco5bEDlPvmOHX0JBxn15Gits+R0lqaQxMvS2r45YvNrW2rmtTd4v7zsjEFNsNsbPd/Ruuu9N4TmEojxm+12I9bjcUzoAAAF4QQAAALwggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwbsKp5ho6RExx07kw19rety2jqbnWs7jWtkGg2rREz7bCSlZbjXtjXaekctc0tKTnKvtaz7kKQjhrVAjY223uFU99rX37b1rmux1WdnuNeGwrbeIcP3RKLxdljb6b5ex3IsJZl+fc7PtrXOGm+rj3Yfda5N7mw09U5OynWuDYVs5xSJiZb6Tvc5EljFAwAYwAggAIAXBBAAwAsCCADgBQEEAPCCAAIAeEEAAQC8IIAAAF4QQAAALwggAIAXBBAAwIsBuwtOKZIcd8EVONZJUpJxB1etod64Jkud7Ybe7muYJEkthvpYmq33oVpbfczwa06SYW+cJNU1uNdu/62tt+Wmkua+MvCD3sYbS0Obe22m8XimWHb1GW6zkpSc7F6bZtzXFjbMbamVpGPGfYdphq95y5EeU++szEb3OVIyTL27u92/ORNl+CL2sAsOADCAmQJo9erVKi4uVlpamtLS0lRSUqJf/epXvR9vb29XWVmZRo0apZSUFC1ZskT19fX9PjQAYPAzBVBBQYHuv/9+7dixQ9u3b9fcuXO1ePFivfXWW5KkO++8U88++6yefvppVVVVqba2Vtdee21cBgcADG6mx4CuuuqqPm//4z/+o1avXq2tW7eqoKBAjz/+uNatW6e5c+dKktasWaNPf/rT2rp1qy655JL+mxoAMOid8mNAPT09evLJJ9Xa2qqSkhLt2LFDXV1dKi0t7a2ZPHmyioqKtGXLlhP26ejoUDQa7XMBAAx95gD6zW9+o5SUFEUiES1fvlzr16/XlClTVFdXp3A4rIyMjD71OTk5qqurO2G/iooKpaen914KCwvNVwIAMPiYA2jSpEnauXOntm3bpttuu01Lly7Vnj17TnmA8vJyNTU19V4OHjx4yr0AAIOH+e+AwuGwJkyYIEmaMWOGfv3rX+t73/uerrvuOnV2dqqxsbHPWVB9fb1yc0/8muaRSESRSMQ+OQBgUDvtvwOKxWLq6OjQjBkzNHz4cG3cuLH3Y3v37tWBAwdUUlJyup8GADDEmM6AysvLtWjRIhUVFam5uVnr1q1TZWWlXnjhBaWnp+vmm2/WypUrlZmZqbS0NN1+++0qKSnhGXAAgI8xBVBDQ4O+8IUv6PDhw0pPT1dxcbFeeOEFfe5zn5MkPfTQQwqFQlqyZIk6Ojq0YMECPfroo6c02Ls1UthxupYM976Vu21z7D/kXpuRYuvdbljHYlk5I0m1Te61xi0/MmxXkSQlDnOvDYdtvRvfd681bpGxLB5RUrqtd8y4GqbNcFtJMa75aTQ88bS729Y7xbBeJ9H4NUmy3hANLOujJKnN8nUxfsNFW1rd5+h0r5WkJEMChLrdd561dQZOdaYAevzxxz/x40lJSVq1apVWrVplaQsAOAuxCw4A4AUBBADwggACAHhBAAEAvCCAAABeEEAAAC8IIACAFwQQAMALAggA4IV5G3a8BcEHKxy6etz/T7dh9UiXcZWIpXe3YWZr7x63zRa9LOXG1ub6mOE/WGqlgXM9rXP3GNflWG5b1tt4yPK9ZryNd3S51yYYVjZJUsiw0sb8g874NYxZjqfhayJJw+J4PWOG4xky/BB6/0+reD78eX4iCcHJKs6wQ4cO8aJ0ADAEHDx4UAUFBSf8+IALoFgsptraWqWmpiohIaH3/dFoVIWFhTp48KDS0tI8ThhfXM+h42y4jhLXc6jpj+sZBIGam5uVn5+vUOjEj/QMuLvgQqHQJyZmWlrakD74H+J6Dh1nw3WUuJ5Dzelez/T0k6+I50kIAAAvCCAAgBeDJoAikYjuueceRSIR36PEFddz6DgbrqPE9RxqzuT1HHBPQgAAnB0GzRkQAGBoIYAAAF4QQAAALwggAIAXBBAAwItBE0CrVq3S2LFjlZSUpFmzZun111/3PVK/+va3v62EhIQ+l8mTJ/se67Rs2rRJV111lfLz85WQkKANGzb0+XgQBLr77ruVl5enESNGqLS0VO+8846fYU/Dya7nsmXLPnZsFy5c6GfYU1RRUaGLL75Yqampys7O1tVXX629e/f2qWlvb1dZWZlGjRqllJQULVmyRPX19Z4mPjUu13POnDkfO57Lly/3NPGpWb16tYqLi3u3HZSUlOhXv/pV78fP1LEcFAH01FNPaeXKlbrnnnv0xhtvaPr06VqwYIEaGhp8j9avzj//fB0+fLj3snnzZt8jnZbW1lZNnz5dq1atOu7HH3jgAT3yyCN67LHHtG3bNo0cOVILFixQe3v7GZ709JzsekrSwoUL+xzbJ5544gxOePqqqqpUVlamrVu36sUXX1RXV5fmz5+v1tbW3po777xTzz77rJ5++mlVVVWptrZW1157rcep7VyupyTdcsstfY7nAw884GniU1NQUKD7779fO3bs0Pbt2zV37lwtXrxYb731lqQzeCyDQWDmzJlBWVlZ79s9PT1Bfn5+UFFR4XGq/nXPPfcE06dP9z1G3EgK1q9f3/t2LBYLcnNzg+9+97u972tsbAwikUjwxBNPeJiwf3z0egZBECxdujRYvHixl3nipaGhIZAUVFVVBUHwwbEbPnx48PTTT/fW/Pa3vw0kBVu2bPE15mn76PUMgiD47Gc/G/zd3/2dv6Hi5Jxzzgn+5V/+5YweywF/BtTZ2akdO3aotLS0932hUEilpaXasmWLx8n63zvvvKP8/HyNHz9eN910kw4cOOB7pLipqalRXV1dn+Oanp6uWbNmDbnjKkmVlZXKzs7WpEmTdNttt+no0aO+RzotTU1NkqTMzExJ0o4dO9TV1dXneE6ePFlFRUWD+nh+9Hp+6Cc/+YmysrI0depUlZeXq62tzcd4/aKnp0dPPvmkWltbVVJSckaP5YDbhv1RR44cUU9Pj3Jycvq8PycnR2+//banqfrfrFmztHbtWk2aNEmHDx/Wvffeq8svv1y7d+9Wamqq7/H6XV1dnSQd97h++LGhYuHChbr22ms1btw47du3T9/85je1aNEibdmyRcOGGV+FbQCIxWK64447dOmll2rq1KmSPjie4XBYGRkZfWoH8/E83vWUpBtvvFFjxoxRfn6+du3apa9//evau3evfvGLX3ic1u43v/mNSkpK1N7erpSUFK1fv15TpkzRzp07z9ixHPABdLZYtGhR77+Li4s1a9YsjRkzRj/96U918803e5wMp+v666/v/fe0adNUXFysc889V5WVlZo3b57HyU5NWVmZdu/ePegfozyZE13PW2+9tfff06ZNU15enubNm6d9+/bp3HPPPdNjnrJJkyZp586dampq0s9+9jMtXbpUVVVVZ3SGAX8XXFZWloYNG/axZ2DU19crNzfX01Txl5GRoYkTJ6q6utr3KHHx4bE7246rJI0fP15ZWVmD8tiuWLFCzz33nF555ZU+r9uVm5urzs5ONTY29qkfrMfzRNfzeGbNmiVJg+54hsNhTZgwQTNmzFBFRYWmT5+u733ve2f0WA74AAqHw5oxY4Y2btzY+75YLKaNGzeqpKTE42Tx1dLSon379ikvL8/3KHExbtw45ebm9jmu0WhU27ZtG9LHVfrgZeePHj06qI5tEARasWKF1q9fr5dfflnjxo3r8/EZM2Zo+PDhfY7n3r17deDAgUF1PE92PY9n586dkjSojufxxGIxdXR0nNlj2a9PaYiTJ598MohEIsHatWuDPXv2BLfeemuQkZER1NXV+R6t33zlK18JKisrg5qamuDVV18NSktLg6ysrKChocH3aKesubk5ePPNN4M333wzkBQ8+OCDwZtvvhm89957QRAEwf333x9kZGQEzzzzTLBr165g8eLFwbhx44L333/f8+Q2n3Q9m5ubg69+9avBli1bgpqamuCll14KLrzwwuC8884L2tvbfY/u7LbbbgvS09ODysrK4PDhw72Xtra23prly5cHRUVFwcsvvxxs3749KCkpCUpKSjxObXey61ldXR3cd999wfbt24OamprgmWeeCcaPHx/Mnj3b8+Q23/jGN4KqqqqgpqYm2LVrV/CNb3wjSEhICP7jP/4jCIIzdywHRQAFQRB8//vfD4qKioJwOBzMnDkz2Lp1q++R+tV1110X5OXlBeFwOPjUpz4VXHfddUF1dbXvsU7LK6+8Ekj62GXp0qVBEHzwVOy77roryMnJCSKRSDBv3rxg7969foc+BZ90Pdva2oL58+cHo0ePDoYPHx6MGTMmuOWWWwbdL0/Hu36SgjVr1vTWvP/++8Hf/M3fBOecc06QnJwcXHPNNcHhw4f9DX0KTnY9Dxw4EMyePTvIzMwMIpFIMGHChODv//7vg6amJr+DG33pS18KxowZE4TD4WD06NHBvHnzesMnCM7cseT1gAAAXgz4x4AAAEMTAQQA8IIAAgB4QQABALwggAAAXhBAAAAvCCAAgBcEEADACwIIAOAFAQQA8IIAAgB48f8BVIVMIQ/F0ccAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "image, label = train_dataset[0]\n",
    "\n",
    "# 确保图像数据类型为 NumPy 数组\n",
    "image = np.array(image)\n",
    "\n",
    "# 显示图像\n",
    "print(f\"Image shape: {image.shape}\")\n",
    "plt.imshow(image.transpose(1, 2, 0))\n",
    "plt.title(label)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 定义训练函数\n",
    "def train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=10):\n",
    "    losses = []\n",
    "    model.to(device)\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()  # 设置模型为训练模式\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            optimizer.zero_grad()  # 梯度清零\n",
    "            outputs = model(inputs)  # 前向传播\n",
    "            loss = criterion(outputs, labels)  # 计算损失\n",
    "            loss.backward()  # 反向传播\n",
    "            optimizer.step()  # 参数更新\n",
    "            running_loss += loss.item()\n",
    "            losses.append(loss.item())\n",
    "\n",
    "        # 打印每个epoch的训练损失\n",
    "        print(f\"Epoch {epoch+1}, Train Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "        # 在验证集上评估模型\n",
    "        model.eval()  # 设置模型为评估模式\n",
    "        val_loss = 0.0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        with torch.no_grad():  # 不计算梯度\n",
    "            for inputs, labels in val_loader:\n",
    "                inputs, labels = inputs.to(device), labels.to(device)\n",
    "                outputs = model(inputs)\n",
    "                loss = criterion(outputs, labels)\n",
    "                val_loss += loss.item()\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        # 打印每个epoch的验证损失和准确率\n",
    "        print(f\"Epoch {epoch+1}, Validation Loss: {val_loss/len(val_loader)}, Validation Accuracy: {(correct/total)*100:.2f}%\")\n",
    "        count = 0\n",
    "        # if (correct/total) > 0.80:\n",
    "        #     count = count + 1\n",
    "        # if count >= 3:\n",
    "        #     break\n",
    "\n",
    "    return losses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_data(model, test_loader, criterion):\n",
    "    model.to(device)\n",
    "    model.eval()  # 设置模型为评估模式\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():  # 不计算梯度\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            test_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "    print(f\"Test Loss: {test_loss/len(test_loader)}, Test Accuracy: {(correct/total)*100:.2f}%\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataloaders: (<torch.utils.data.dataloader.DataLoader object at 0x000001B60CC4B3D0>, <torch.utils.data.dataloader.DataLoader object at 0x000001B60CCAB5D0>)\n",
      "Length of 训练集: 625, batches of 64\n",
      "Length of 验证集: 157, batches of 64\n",
      "Length of 测试集: 157, batches of 64\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import DataLoader, random_split\n",
    "\n",
    "# 设置批处理大小超参数\n",
    "BATCH_SIZE = 64\n",
    "\n",
    "# 定义数据加载器\n",
    "train_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True, num_workers=4)\n",
    "val_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "test_loader = DataLoader(test_dataset, batch_size=BATCH_SIZE, shuffle=False, num_workers=4)\n",
    "\n",
    "#打印结果\n",
    "print(f\"Dataloaders: {train_loader, test_loader}\")\n",
    "print(f\"Length of 训练集: {len(train_loader)}, batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of 验证集: {len(val_loader)}, batches of {BATCH_SIZE}\")\n",
    "print(f\"Length of 测试集: {len(test_loader)}, batches of {BATCH_SIZE}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet9"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ResNet9(\n",
      "  (prep): Sequential(\n",
      "    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "  )\n",
      "  (layer1): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(64, 128, kernel_size=(1, 1), stride=(1, 1))\n",
      "        (1): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer2): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(128, 256, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(128, 256, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (layer3): Sequential(\n",
      "    (0): ResidualBlock(\n",
      "      (conv1): Conv2d(256, 512, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1))\n",
      "      (bn1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (conv2): Conv2d(512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))\n",
      "      (bn2): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      (relu): ReLU(inplace=True)\n",
      "      (shortcut): Sequential(\n",
      "        (0): Conv2d(256, 512, kernel_size=(1, 1), stride=(2, 2))\n",
      "        (1): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (classifier): Sequential(\n",
      "    (0): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    (1): Conv2d(512, 10, kernel_size=(1, 1), stride=(1, 1))\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, padding=1, stride=stride)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, padding=1)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.stride = stride\n",
    "\n",
    "        # For shortcut connection\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        else:\n",
    "            self.shortcut = nn.Sequential()\n",
    "\n",
    "    def forward(self, x):\n",
    "        residual = x\n",
    "\n",
    "        out = self.conv1(x)\n",
    "        out = self.bn1(out)\n",
    "        out = self.relu(out)\n",
    "\n",
    "        out = self.conv2(out)\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # Shortcut connection\n",
    "        residual = self.shortcut(residual)\n",
    "\n",
    "        out += residual\n",
    "        out = self.relu(out)\n",
    "\n",
    "        return out\n",
    "\n",
    "class ResNet9(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ResNet9, self).__init__()\n",
    "        self.prep = nn.Sequential(\n",
    "            nn.Conv2d(3, 64, kernel_size=3, padding=1),\n",
    "            nn.BatchNorm2d(64),\n",
    "            nn.ReLU(inplace=True)\n",
    "        )\n",
    "        self.layer1 = self._make_layer(64, 128, stride=1)\n",
    "        self.layer2 = self._make_layer(128, 256, stride=2)\n",
    "        self.layer3 = self._make_layer(256, 512, stride=2)\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.AdaptiveAvgPool2d((1, 1)),\n",
    "            nn.Conv2d(512, num_classes, kernel_size=1)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, stride):\n",
    "        layers = []\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride))\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.prep(x)\n",
    "        out = self.layer1(out)\n",
    "        out = self.layer2(out)\n",
    "        out = self.layer3(out)\n",
    "        out = self.classifier(out)\n",
    "        out = out.view(out.size(0), -1)\n",
    "        return F.log_softmax(out, dim=1)\n",
    "\n",
    "# 创建 ResNet-9 模型实例\n",
    "resnet9 = ResNet9()\n",
    "# 打印模型结构\n",
    "print(resnet9)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.3068763389587403\n",
      "Epoch 1, Validation Loss: 1.2370467334036614, Validation Accuracy: 54.56%\n",
      "Epoch 2, Train Loss: 0.9089806944847106\n",
      "Epoch 2, Validation Loss: 0.8895441980878259, Validation Accuracy: 68.95%\n",
      "Epoch 3, Train Loss: 0.7282590817451478\n",
      "Epoch 3, Validation Loss: 0.7515919016804665, Validation Accuracy: 73.65%\n",
      "Epoch 4, Train Loss: 0.6010240538597107\n",
      "Epoch 4, Validation Loss: 0.7806165829585616, Validation Accuracy: 73.27%\n",
      "Epoch 5, Train Loss: 0.5009850335836411\n",
      "Epoch 5, Validation Loss: 0.7808399010615744, Validation Accuracy: 74.53%\n",
      "Epoch 6, Train Loss: 0.40948437273502347\n",
      "Epoch 6, Validation Loss: 0.8692299919143603, Validation Accuracy: 72.05%\n",
      "Epoch 7, Train Loss: 0.33366934468746184\n",
      "Epoch 7, Validation Loss: 0.710957637258396, Validation Accuracy: 76.13%\n",
      "Epoch 8, Train Loss: 0.25679034032821657\n",
      "Epoch 8, Validation Loss: 0.7796242531317814, Validation Accuracy: 76.36%\n",
      "Epoch 9, Train Loss: 0.19029173107743264\n",
      "Epoch 9, Validation Loss: 0.7914146923335494, Validation Accuracy: 76.08%\n",
      "Epoch 10, Train Loss: 0.1374682373970747\n",
      "Epoch 10, Validation Loss: 0.6698088642138584, Validation Accuracy: 80.34%\n",
      "Epoch 11, Train Loss: 0.10581410587131977\n",
      "Epoch 11, Validation Loss: 1.0107709626862957, Validation Accuracy: 75.36%\n",
      "Epoch 12, Train Loss: 0.06711454674899578\n",
      "Epoch 12, Validation Loss: 0.8357357602020737, Validation Accuracy: 78.85%\n",
      "Epoch 13, Train Loss: 0.051679762826114896\n",
      "Epoch 13, Validation Loss: 0.9838749456937146, Validation Accuracy: 77.62%\n",
      "Epoch 14, Train Loss: 0.03545425524264574\n",
      "Epoch 14, Validation Loss: 0.9877393608260306, Validation Accuracy: 78.10%\n",
      "Epoch 15, Train Loss: 0.030555890208855272\n",
      "Epoch 15, Validation Loss: 0.8777367700437072, Validation Accuracy: 79.87%\n",
      "Epoch 16, Train Loss: 0.021013114545866848\n",
      "Epoch 16, Validation Loss: 0.7566275706716404, Validation Accuracy: 82.10%\n",
      "Epoch 17, Train Loss: 0.013170360280945898\n",
      "Epoch 17, Validation Loss: 0.7160041309466028, Validation Accuracy: 82.75%\n",
      "Epoch 18, Train Loss: 0.00665324950478971\n",
      "Epoch 18, Validation Loss: 0.7986487865827645, Validation Accuracy: 81.97%\n",
      "Epoch 19, Train Loss: 0.002225808255560696\n",
      "Epoch 19, Validation Loss: 0.6815443069312224, Validation Accuracy: 83.95%\n",
      "Epoch 20, Train Loss: 0.001064227312989533\n",
      "Epoch 20, Validation Loss: 0.6916427729046268, Validation Accuracy: 84.36%\n",
      "Epoch 21, Train Loss: 0.0007465878399088979\n",
      "Epoch 21, Validation Loss: 0.695378234906561, Validation Accuracy: 84.46%\n",
      "Epoch 22, Train Loss: 0.0006098105216398835\n",
      "Epoch 22, Validation Loss: 0.6997420698594136, Validation Accuracy: 84.50%\n",
      "Epoch 23, Train Loss: 0.0005199062522035093\n",
      "Epoch 23, Validation Loss: 0.7011791799858118, Validation Accuracy: 84.35%\n",
      "Epoch 24, Train Loss: 0.0004932467547478154\n",
      "Epoch 24, Validation Loss: 0.7052232778755723, Validation Accuracy: 84.42%\n",
      "Epoch 25, Train Loss: 0.00044262157297926026\n",
      "Epoch 25, Validation Loss: 0.7103621431976367, Validation Accuracy: 84.53%\n",
      "Epoch 26, Train Loss: 0.00040889405795605855\n",
      "Epoch 26, Validation Loss: 0.7124323348520668, Validation Accuracy: 84.38%\n",
      "Epoch 27, Train Loss: 0.0003630910868989304\n",
      "Epoch 27, Validation Loss: 0.7203517464125991, Validation Accuracy: 84.31%\n",
      "Epoch 28, Train Loss: 0.0003416993825114332\n",
      "Epoch 28, Validation Loss: 0.7225190163797633, Validation Accuracy: 84.57%\n",
      "Epoch 29, Train Loss: 0.00033122666240669786\n",
      "Epoch 29, Validation Loss: 0.7227939553321547, Validation Accuracy: 84.23%\n",
      "Epoch 30, Train Loss: 0.00029309629205381496\n",
      "Epoch 30, Validation Loss: 0.7195637601006563, Validation Accuracy: 84.49%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "optimizer = optim.SGD(resnet9.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "# optimizer = optim.Adam(model_Res.parameters(), lr=0.001)\n",
    "\n",
    "val_losses = train_model(resnet9, train_loader, val_loader, criterion, optimizer, num_epochs=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.7202756092616707, Test Accuracy: 84.11%\n"
     ]
    }
   ],
   "source": [
    "test_data(model=resnet9, test_loader=test_loader, criterion=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resnet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1, downsample=None):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=5, stride=stride, padding=2, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.relu = nn.ReLU(inplace=True)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=5, stride=1, padding=2, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.downsample = downsample\n",
    "\n",
    "    def forward(self, x):\n",
    "        # 保存输入 x 作为恒等映射（identity），用于在残差连接中与输出相加\n",
    "        identity = x\n",
    "\n",
    "        # 第一个卷积层的前向传播\n",
    "        out = self.conv1(x)\n",
    "        # 对第一个卷积层的输出进行批量归一化\n",
    "        out = self.bn1(out)\n",
    "        # 对批量归一化后的结果应用 ReLU 激活函数\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # 第二个卷积层的前向传播\n",
    "        out = self.conv2(out)\n",
    "        # 对第二个卷积层的输出进行批量归一化\n",
    "        out = self.bn2(out)\n",
    "\n",
    "        # 如果存在 downsample（残差连接中的下采样操作），则对输入 x 进行下采样\n",
    "        if self.downsample is not None:\n",
    "            identity = self.downsample(x)\n",
    "\n",
    "        # 将残差连接的结果与输入相加\n",
    "        out += identity\n",
    "        # 对相加后的结果应用 ReLU 激活函数\n",
    "        out = self.relu(out)\n",
    "\n",
    "        # 返回最终的输出\n",
    "        return out\n",
    "\n",
    "class CNN_ResNet(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        # 调用父类（nn.Module）的构造函数，初始化模型的基本结构\n",
    "        super(CNN_ResNet, self).__init__()\n",
    "\n",
    "        # 第一个卷积块，包括一个卷积层、ReLU 激活函数和最大池化层\n",
    "        self.conv1 = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=5, stride=1, padding=2),  # 输入通道为 3，输出通道为 16，卷积核大小为 5x5，填充为 2\n",
    "            nn.ReLU(),  # ReLU 激活函数\n",
    "            nn.MaxPool2d(kernel_size=2)  # 最大池化层，池化核大小为 2x2\n",
    "        )\n",
    "\n",
    "        # 使用 make_layer 方法构建第二、第三和第四个残差块\n",
    "        self.conv2 = self.make_layer(16, 32, stride=1)  # 构建残差块，输入通道为 16，输出通道为 32，步长为 1\n",
    "        self.conv3 = self.make_layer(32, 64, stride=1)  # 构建残差块，输入通道为 32，输出通道为 64，步长为 1\n",
    "        self.conv4 = self.make_layer(64, 128, stride=1)  # 构建残差块，输入通道为 64，输出通道为 128，步长为 1\n",
    "\n",
    "        # 全局平均池化层，将特征图大小调整为 (1, 1)\n",
    "        self.avgpool = nn.AdaptiveAvgPool2d((1, 1))\n",
    "\n",
    "        # 全连接层，将最后一层特征图压缩为长度为 num_classes 的向量，用于分类\n",
    "        self.fc = nn.Linear(128, num_classes)  # 输入大小为 128，输出大小为分类类别数\n",
    "\n",
    "    def make_layer(self, in_channels, out_channels, stride):\n",
    "        # 初始化 downsample 为 None，用于存储下采样操作\n",
    "        downsample = None\n",
    "        # 如果步长不为 1 或者输入通道数不等于输出通道数，则需要进行下采样操作\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            # 构建下采样操作，包括一个卷积层和一个批量归一化层\n",
    "            downsample = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "        # 初始化残差块层列表\n",
    "        layers = []\n",
    "        # 将构建好的残差块添加到列表中\n",
    "        layers.append(ResidualBlock(in_channels, out_channels, stride, downsample))\n",
    "        # 将列表转换为序列，并返回\n",
    "        return nn.Sequential(*layers)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        x = self.conv4(x)\n",
    "        x = self.avgpool(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.fc(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.3340047006607056\n",
      "Epoch 1, Validation Loss: 1.1853217399044402, Validation Accuracy: 57.19%\n",
      "Epoch 2, Train Loss: 0.9775206230163574\n",
      "Epoch 2, Validation Loss: 1.067211603283123, Validation Accuracy: 62.39%\n",
      "Epoch 3, Train Loss: 0.8248997010231018\n",
      "Epoch 3, Validation Loss: 0.933307798045456, Validation Accuracy: 67.50%\n",
      "Epoch 4, Train Loss: 0.7204245248317719\n",
      "Epoch 4, Validation Loss: 0.8753282816926385, Validation Accuracy: 69.66%\n",
      "Epoch 5, Train Loss: 0.6401915470600128\n",
      "Epoch 5, Validation Loss: 0.7141675546670415, Validation Accuracy: 75.36%\n",
      "Epoch 6, Train Loss: 0.5754885333776474\n",
      "Epoch 6, Validation Loss: 0.6828022587830853, Validation Accuracy: 76.99%\n",
      "Epoch 7, Train Loss: 0.5265835210323334\n",
      "Epoch 7, Validation Loss: 0.6559085435928054, Validation Accuracy: 77.52%\n",
      "Epoch 8, Train Loss: 0.4808338764667511\n",
      "Epoch 8, Validation Loss: 0.6699856980970711, Validation Accuracy: 77.75%\n",
      "Epoch 9, Train Loss: 0.43991200037002565\n",
      "Epoch 9, Validation Loss: 0.7366440074079356, Validation Accuracy: 76.45%\n",
      "Epoch 10, Train Loss: 0.40304398522377016\n",
      "Epoch 10, Validation Loss: 0.695243986928539, Validation Accuracy: 77.16%\n",
      "Epoch 11, Train Loss: 0.36662458283901217\n",
      "Epoch 11, Validation Loss: 0.6084041162660927, Validation Accuracy: 79.71%\n",
      "Epoch 12, Train Loss: 0.33192430500984194\n",
      "Epoch 12, Validation Loss: 0.7059583282394774, Validation Accuracy: 77.70%\n",
      "Epoch 13, Train Loss: 0.29972464834451673\n",
      "Epoch 13, Validation Loss: 0.7073742685614118, Validation Accuracy: 78.11%\n",
      "Epoch 14, Train Loss: 0.2765162125587463\n",
      "Epoch 14, Validation Loss: 0.651872867042092, Validation Accuracy: 79.39%\n",
      "Epoch 15, Train Loss: 0.2460176785826683\n",
      "Epoch 15, Validation Loss: 0.6335396214275603, Validation Accuracy: 80.68%\n",
      "Epoch 16, Train Loss: 0.21863712840676308\n",
      "Epoch 16, Validation Loss: 0.6576618370926304, Validation Accuracy: 80.48%\n",
      "Epoch 17, Train Loss: 0.19307109888792037\n",
      "Epoch 17, Validation Loss: 0.701465008934592, Validation Accuracy: 79.04%\n",
      "Epoch 18, Train Loss: 0.17490972203910352\n",
      "Epoch 18, Validation Loss: 0.7827778924612483, Validation Accuracy: 78.13%\n",
      "Epoch 19, Train Loss: 0.15917214846014976\n",
      "Epoch 19, Validation Loss: 0.757509429363688, Validation Accuracy: 79.61%\n",
      "Epoch 20, Train Loss: 0.13791939297914504\n",
      "Epoch 20, Validation Loss: 0.795573906534037, Validation Accuracy: 79.02%\n",
      "Epoch 21, Train Loss: 0.11377434160113335\n",
      "Epoch 21, Validation Loss: 0.7620976506524785, Validation Accuracy: 79.92%\n",
      "Epoch 22, Train Loss: 0.09895825389772654\n",
      "Epoch 22, Validation Loss: 0.8337035464822866, Validation Accuracy: 79.46%\n",
      "Epoch 23, Train Loss: 0.09656091436445713\n",
      "Epoch 23, Validation Loss: 0.746236067289, Validation Accuracy: 81.00%\n",
      "Epoch 24, Train Loss: 0.0831144967764616\n",
      "Epoch 24, Validation Loss: 0.8528480235558407, Validation Accuracy: 79.12%\n",
      "Epoch 25, Train Loss: 0.07723259197622538\n",
      "Epoch 25, Validation Loss: 0.8757195814399962, Validation Accuracy: 79.90%\n",
      "Epoch 26, Train Loss: 0.06988868616819381\n",
      "Epoch 26, Validation Loss: 0.8527830252601842, Validation Accuracy: 79.72%\n",
      "Epoch 27, Train Loss: 0.07011916716396809\n",
      "Epoch 27, Validation Loss: 0.9672025821770832, Validation Accuracy: 78.37%\n",
      "Epoch 28, Train Loss: 0.05931764477714896\n",
      "Epoch 28, Validation Loss: 0.9315372289745671, Validation Accuracy: 79.92%\n",
      "Epoch 29, Train Loss: 0.05427370472103357\n",
      "Epoch 29, Validation Loss: 0.8457783016429585, Validation Accuracy: 81.18%\n",
      "Epoch 30, Train Loss: 0.03932066934555769\n",
      "Epoch 30, Validation Loss: 0.8341302047869202, Validation Accuracy: 81.53%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "model_Res = CNN_ResNet()\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "optimizer = optim.SGD(model_Res.parameters(), lr=0.01, momentum=0.9, nesterov=True)\n",
    "# optimizer = optim.Adam(model_Res.parameters(), lr=0.001)\n",
    "\n",
    "val_losses = train_model(model_Res, train_loader, val_loader, criterion, optimizer, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.8757081992307286, Test Accuracy: 80.93%\n"
     ]
    }
   ],
   "source": [
    "test_data(model=model_Res, test_loader=test_loader, criterion=criterion)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "'''开始建立CNN网络'''\n",
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN,self).__init__()\n",
    "        '''\n",
    "        一般来说，卷积网络包括以下内容：\n",
    "        1.卷积层\n",
    "        2.神经网络\n",
    "        3.池化层\n",
    "        '''\n",
    "        self.conv1=nn.Sequential(\n",
    "            nn.Conv2d(              #--> (3, 32, 32)\n",
    "                in_channels=3,      #传入RGB为三层\n",
    "                out_channels=16,    #输出的图片是几层\n",
    "                kernel_size=5,      #代表扫描的区域点为3*3\n",
    "                stride=1,           #就是每隔多少步跳一下\n",
    "                padding=2,          #边框补全，其计算公式=（kernel_size-1）/2=(5-1)/2=2\n",
    "            ),    # 2d代表二维卷积           --> (16, 32, 32)\n",
    "            nn.ReLU(),              #非线性激活层\n",
    "            nn.MaxPool2d(kernel_size=2),    #设定这里的扫描区域为2*2，且取出该2*2中的最大值          --> (16, 16, 16)\n",
    "        )\n",
    " \n",
    "        self.conv2=nn.Sequential(\n",
    "            nn.Conv2d(              #       --> (16, 16, 16)\n",
    "                in_channels=16,     #这里的输入是上层的输出为16层\n",
    "                out_channels=32,    #在这里我们需要将其输出为32层\n",
    "                kernel_size=5,      #代表扫描的区域点为5*5\n",
    "                stride=1,           #就是每隔多少步跳一下\n",
    "                padding=2,          #边框补全，其计算公式=（kernel_size-1）/2=(5-1)/2=\n",
    "            ),                      #   --> (32, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2),    #设定这里的扫描区域为2*2，且取出该2*2中的最大值     --> (32, 8, 8)，这里是三维数据\n",
    "        )\n",
    "\n",
    "        self.conv3=nn.Sequential(\n",
    "            nn.Conv2d(              #       --> (32, 16, 16)\n",
    "                in_channels=32,     #这里的输入是上层的输出为32层\n",
    "                out_channels=64,    #在这里我们需要将其输出为64层\n",
    "                kernel_size=3,      #代表扫描的区域点为3*3\n",
    "                stride=1,           #就是每隔多少步跳一下\n",
    "                padding=1,          #边框补全，其计算公式=（kernel_size-1）/2=(3-1)/2=\n",
    "            ),                      #   --> (64, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            # nn.MaxPool2d(kernel_size=2),    #设定这里的扫描区域为2*2，且取出该2*2中的最大值     --> (64, 4, 4)，这里是三维数据\n",
    "        )\n",
    "\n",
    "        self.conv4=nn.Sequential(\n",
    "            nn.Conv2d(              #       --> (64, 16, 16)\n",
    "                in_channels=64,     #这里的输入是上层的输出为64层\n",
    "                out_channels=128,    #在这里我们需要将其输出为128层\n",
    "                kernel_size=5,      #代表扫描的区域点为3*3\n",
    "                stride=1,           #就是每隔多少步跳一下\n",
    "                padding=2,          #边框补全，其计算公式=（kernel_size-1）/2=(3-1)/2=\n",
    "            ),                      #   --> (128, 16, 16)\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2),    #设定这里的扫描区域为2*2，且取出该2*2中的最大值     --> (128, 16, 16)，这里是三维数据\n",
    "        )\n",
    " \n",
    "        self.out=nn.Linear(128*8*8,10)       #注意一下这里的数据是二维的数据\n",
    " \n",
    "    def forward(self,x):\n",
    "        x=self.conv1(x)\n",
    "        x=self.conv2(x)     #（batch,32, 8, 8）\n",
    "        x=self.conv3(x)\n",
    "        x=self.conv4(x)\n",
    "        #然后接下来进行一下扩展展平的操作，将三维数据转为二维的数据\n",
    "        x=x.view(x.size(0),-1)    \n",
    "        x=self.out(x)\n",
    "        return x\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1, Train Loss: 1.4688179598808289\n",
      "Epoch 1, Validation Loss: 1.1913261516079021, Validation Accuracy: 57.57%\n",
      "Epoch 2, Train Loss: 1.0878320751190185\n",
      "Epoch 2, Validation Loss: 1.0254249754984668, Validation Accuracy: 63.75%\n",
      "Epoch 3, Train Loss: 0.893797371006012\n",
      "Epoch 3, Validation Loss: 0.9689578797407211, Validation Accuracy: 67.02%\n",
      "Epoch 4, Train Loss: 0.7628002008914948\n",
      "Epoch 4, Validation Loss: 0.8564041983929409, Validation Accuracy: 70.35%\n",
      "Epoch 5, Train Loss: 0.6545688506603241\n",
      "Epoch 5, Validation Loss: 0.8229674750072941, Validation Accuracy: 71.97%\n",
      "Epoch 6, Train Loss: 0.5655449935913086\n",
      "Epoch 6, Validation Loss: 0.8476263821884326, Validation Accuracy: 72.51%\n",
      "Epoch 7, Train Loss: 0.48239095149040223\n",
      "Epoch 7, Validation Loss: 0.8816279083680195, Validation Accuracy: 72.61%\n",
      "Epoch 8, Train Loss: 0.3958609107851982\n",
      "Epoch 8, Validation Loss: 0.9618259679739642, Validation Accuracy: 71.51%\n",
      "Epoch 9, Train Loss: 0.33020731328725816\n",
      "Epoch 9, Validation Loss: 1.0576021101824038, Validation Accuracy: 70.75%\n",
      "Epoch 10, Train Loss: 0.2725963952302933\n",
      "Epoch 10, Validation Loss: 1.0803414805299918, Validation Accuracy: 71.85%\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "# 创建模型实例                                                                                                                                      \n",
    "model = CNN()\n",
    "\n",
    "# 定义损失函数和优化器\n",
    "criterion = nn.CrossEntropyLoss()   \n",
    "optimizer = optim.SGD(lr=0.01, momentum=0.9, nesterov=True)\n",
    "\n",
    "# 训练模型\n",
    "val_losses = train_model(model, train_loader, val_loader, criterion, optimizer, num_epochs=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 1.1159870229708921, Test Accuracy: 70.29%\n"
     ]
    }
   ],
   "source": [
    "# 测试集\n",
    "# 在验证集上评估模型\n",
    "model.eval()  # 设置模型为评估模式\n",
    "test_loss = 0.0\n",
    "correct = 0\n",
    "total = 0\n",
    "with torch.no_grad():  # 不计算梯度\n",
    "    for inputs, labels in test_loader:\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        test_loss += loss.item()\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "print(f\"Test Loss: {test_loss/len(test_loader)}, Test Accuracy: {(correct/total)*100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
